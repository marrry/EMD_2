{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Input, Embedding, Dropout, Activation, GRU, Bidirectional, GlobalMaxPool1D, LSTM, Softmax, GlobalAveragePooling1D\n",
    "from keras.models import Model, Sequential\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import Adam, SGD\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_file=f'glove.6B.200d.txt'\n",
    "train = pd.read_csv('train_clean.csv', sep=';', encoding='utf-8')\n",
    "test = pd.read_csv('test_clean.csv', sep=';', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_nans = test.loc[test['cleaned_string']=='Not Available']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_dimensions = 200\n",
    "embeddings_words = 10000\n",
    "comment_length = 70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train[\"cleaned_string\"].fillna(\"_na_\").values\n",
    "Y_train = to_categorical(train.Category)\n",
    "test_data = test[\"cleaned_string\"].fillna(\"_na_\").values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=embeddings_words)\n",
    "tokenizer.fit_on_texts(list(train_data))\n",
    "train_tokenized = tokenizer.texts_to_sequences(train_data)\n",
    "test_tokenized = tokenizer.texts_to_sequences(test_data)\n",
    "X_train = pad_sequences(train_tokenized, maxlen=comment_length)\n",
    "X_test = pad_sequences(test_tokenized, maxlen=comment_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')\n",
    "embeddings_index = dict(get_coefs(*o.strip().split()) for o in open(embedding_file, encoding=\"utf8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_embeddings = np.stack(embeddings_index.values())\n",
    "embeddings_mean, embeddings_std = all_embeddings.mean(), all_embeddings.std()\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "how_many_words = min(embeddings_words, len(word_index))\n",
    "embedding_matrix = np.random.normal(embeddings_mean, embeddings_std, (how_many_words, embeddings_dimensions))\n",
    "for word, i in word_index.items():\n",
    "    if i >= embeddings_words: continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None: embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = Input(shape=(comment_length,))\n",
    "emb_layer = Embedding(embeddings_words, embeddings_dimensions, weights=[embedding_matrix])(input_layer)\n",
    "bidir_layer = Bidirectional(GRU(64, return_sequences=True, dropout=0.25, recurrent_dropout=0.05))(emb_layer)\n",
    "max_pool = GlobalMaxPool1D()(bidir_layer)\n",
    "dense_2 = Dense(3, activation=\"sigmoid\")(max_pool)\n",
    "model = Model(inputs=input_layer, outputs=dense_2)\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "input_layer = Input(shape=(comment_length,))\n",
    "emb_layer = Embedding(embeddings_words, embeddings_dimensions, weights=[embedding_matrix])(input_layer)\n",
    "bidir_layer = Bidirectional(LSTM(128, return_sequences=True))(emb_layer)#, dropout=0.1, recurrent_dropout=0.05))(emb_layer)\n",
    "max_pool = GlobalMaxPool1D()(bidir_layer)\n",
    "dense_1 = Dense(64, activation=\"relu\")(max_pool)\n",
    "#dropout = Dropout(0.2)(dense_1)\n",
    "dense_2 = Dense(3, activation=\"sigmoid\")(dense_1)#(dropout)\n",
    "model = Model(inputs=input_layer, outputs=dense_2)\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = model.fit(X_train, Y_train, batch_size=32, epochs=2, validation_split=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test = model.predict([X_test], batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_classes = np.argmax(Y_test, axis=1)\n",
    "Y_classes[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(test.Id)\n",
    "submission['Category'] = Y_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {0: 'neutral', 1: 'positive', 2: 'negative'}\n",
    "submission = submission.replace({'Category': mapping})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_nans.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in test_nans.index:\n",
    "    submission.loc[i, 'Category'] = 'positive'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'submission'+time.strftime(\"%Y%m%d-%H%M%S\")+'.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(filename, index=False, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
